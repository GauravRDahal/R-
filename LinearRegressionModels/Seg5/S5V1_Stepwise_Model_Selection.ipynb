{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Stepwise Model Selection**\n",
        "\n",
        "Models can be compared based on preformance metrics such as:\n",
        "- adjusted R-squared statistic,\n",
        "- prediction error using cross validation,\n",
        "- model scores such as AIC, BIC (smaller the better)\n",
        "\n",
        "In general, we would like to have models that:\n",
        "- are simple (few predictors/covariates)\n",
        "- generalize well on unseen test data\n",
        "- are interpretable\n",
        "\n",
        "### How do we select a model among many available models that have these attributes?\n",
        "\n",
        "One possible way to select the model is using the `\"Forward Stepwise Selection\".`\n",
        "\n",
        "## Forward Stepwise Selection\n",
        "1. Start with an intercept only model excluding any of the other predictor.\n",
        "\n",
        "`Yhat = B0hat`\n",
        "2. **Add** the single predictor that leads to the greatest reduction in the chosen model score (AIC / BIC).\n",
        "3. Repeate step-2 until there is no improvement in the model score.\n",
        "\n",
        "Here, we are adding the predictors sequentially and at each step checking what is the best predictor at that stage which is determined by using the notion of performance matrics (model score). We choose the predictor that results in the greatest reduction in the model scores. And we repeat the process until we see no improvement in the model score.\n",
        "\n",
        "- Computational complexity is Quadratic in the number of predictors.\n",
        "\n",
        "It is probablly not the best way to determine what the ideal model is."
      ],
      "metadata": {
        "id": "zeZMIOG6R3sT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backward Stepwise Selection:\n",
        "\n",
        "1. We start with a model that includes all predictors.\n",
        "2. **DELETE** the single predictor that leads to the greatest reduction in the chosen model score.\n",
        "3. Repeat step-2 until there is no improvement in the model score.\n",
        "\n",
        "- Computational complexity is again Quadratic in the numebr of predictors.\n",
        "\n",
        "Backward stepwise cannot be used when the number of samples are less than or equal to tye number of predictors as the design matrix will have linearly dependent columns.\n",
        "\n",
        "((((\n",
        "  \n",
        "- Matrix which has more columns than rows is gurantted to have its columns to be linearly dependent, so that the columns will not be linearly independent anymore.\n",
        "- (X_transpose X)inverse is no more invertible so the OLSE cannot be calculated.\n",
        "\n",
        "))))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "maCXZcFzVtGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's look at this using the bodyfat dataset inside the mplot package"
      ],
      "metadata": {
        "id": "j5iw9xmEazpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(c(\"ggplot2\", \"dplyr\", \"mplot\", \"reshape\", \"leaps\"))\n",
        "library(ggplot2)\n",
        "library(dplyr)\n",
        "library(mplot)\n",
        "library(reshape) # to melt the dataframe\n",
        "library(leaps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNObaDWyR4C5",
        "outputId": "0b7a81f6-5a2a-4a48-cfa4-bc213b4a5c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing packages into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘iterators’, ‘grpreg’, ‘pls’, ‘rngtools’, ‘shape’, ‘RcppEigen’, ‘foreach’, ‘bestglm’, ‘doParallel’, ‘doRNG’, ‘plyr’, ‘shinydashboard’, ‘glmnet’, ‘googleVis’, ‘reshape2’\n",
            "\n",
            "\n",
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n",
            "\n",
            "Attaching package: ‘reshape’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:dplyr’:\n",
            "\n",
            "    rename\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading bodyfat data\n",
        "data('bofyfat', package = 'mplot')\n",
        "bfData = bodyfat %>% select(-c('Id')) #removing Id column\n",
        "str(bfData)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71UV6FuyR9Zb",
        "outputId": "458b6ef2-cbea-4305-9191-ad5fc2bf6c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in data(\"bofyfat\", package = \"mplot\"):\n",
            "“data set ‘bofyfat’ not found”\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'data.frame':\t128 obs. of  14 variables:\n",
            " $ Bodyfat: num  6.3 11.3 14.2 14.8 8 11.5 15.4 15.1 17.3 22.1 ...\n",
            " $ Age    : int  54 50 24 55 51 54 58 34 28 35 ...\n",
            " $ Weight : num  70.4 73.7 70.8 76.9 62.3 ...\n",
            " $ Height : num  69.2 66.5 70.8 68.2 67.8 ...\n",
            " $ Neck   : num  37.5 38.7 35.7 37.2 36.5 37.4 38 36 35.6 40.5 ...\n",
            " $ Chest  : num  89.3 99.4 92.7 101.7 89.7 ...\n",
            " $ Abdo   : num  78.4 86.7 81.9 91.1 82 87.6 88.1 83.4 83.5 96.4 ...\n",
            " $ Hip    : num  96.1 96.2 95.3 97.1 89.1 ...\n",
            " $ Thigh  : num  56 62.1 56.4 56.6 49.3 59.7 57.1 52.4 57.3 69 ...\n",
            " $ Knee   : num  37.4 39.3 36.5 38.5 33.7 40.2 38.9 35.6 37.8 39 ...\n",
            " $ Ankle  : num  22.4 23.3 22 22.6 21.4 23.4 23.6 20.4 21.7 23.1 ...\n",
            " $ Bic    : num  32.6 30.6 33.5 33.4 29.6 27.9 30.9 28.3 32.2 36.1 ...\n",
            " $ Fore   : num  28.1 27.8 28.3 29.3 26 27 29.6 26.2 27.7 30.5 ...\n",
            " $ Wrist  : num  18.1 18.2 17.3 18.8 16.9 17.8 18 16.5 17.7 18.2 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features in bfData\n",
        "colnames(bfData)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "wESbiEjaR4EH",
        "outputId": "497a4fce-7b1c-4e31-8830-c0e0b1d561d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'Bodyfat'</li><li>'Age'</li><li>'Weight'</li><li>'Height'</li><li>'Neck'</li><li>'Chest'</li><li>'Abdo'</li><li>'Hip'</li><li>'Thigh'</li><li>'Knee'</li><li>'Ankle'</li><li>'Bic'</li><li>'Fore'</li><li>'Wrist'</li></ol>\n"
            ],
            "text/markdown": "1. 'Bodyfat'\n2. 'Age'\n3. 'Weight'\n4. 'Height'\n5. 'Neck'\n6. 'Chest'\n7. 'Abdo'\n8. 'Hip'\n9. 'Thigh'\n10. 'Knee'\n11. 'Ankle'\n12. 'Bic'\n13. 'Fore'\n14. 'Wrist'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'Bodyfat'\n\\item 'Age'\n\\item 'Weight'\n\\item 'Height'\n\\item 'Neck'\n\\item 'Chest'\n\\item 'Abdo'\n\\item 'Hip'\n\\item 'Thigh'\n\\item 'Knee'\n\\item 'Ankle'\n\\item 'Bic'\n\\item 'Fore'\n\\item 'Wrist'\n\\end{enumerate*}\n",
            "text/plain": [
              " [1] \"Bodyfat\" \"Age\"     \"Weight\"  \"Height\"  \"Neck\"    \"Chest\"   \"Abdo\"   \n",
              " [8] \"Hip\"     \"Thigh\"   \"Knee\"    \"Ankle\"   \"Bic\"     \"Fore\"    \"Wrist\"  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "rtTpDByVdCAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making a boxplot excluding the ID column\n",
        "ggplot(data = melt(bfData), aes(x = factor(variable), y = value)) +\n",
        "  geom_boxplot() +\n",
        "    facet_wrap(~variable, scale = 'free')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "FC54CiZ_R4JB",
        "outputId": "46c25ab7-074f-405b-dbb5-613cb26e2546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using  as id variables\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plot without title"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC+lBMVEUAAAABAQECAgIDAwME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\nQmCC"
          },
          "metadata": {
            "image/png": {
              "width": 420,
              "height": 420
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can see boxplots that tell us what kind of distribution each one of these variables have. This explanatory plots helps us understand how the feature in the dataset look like.\n",
        "\n",
        "# Building A Linear Regression Model"
      ],
      "metadata": {
        "id": "zTLL2PQ-d-IV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As abdominal circumference is a good indicator of bocy fat\n",
        "model = lm(data = bfData, Bodyfat ~ Abdo)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "0FQmHyRGR4KN",
        "outputId": "7e14f56b-8a2f-4ff9-8747-30dea9a94dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Bodyfat ~ Abdo, data = bfData)\n",
              "\n",
              "Residuals:\n",
              "     Min       1Q   Median       3Q      Max \n",
              "-10.3542  -2.9928   0.2191   2.4967  10.0106 \n",
              "\n",
              "Coefficients:\n",
              "             Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept) -43.19058    3.63431  -11.88   <2e-16 ***\n",
              "Abdo          0.67411    0.03907   17.26   <2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 4.249 on 126 degrees of freedom\n",
              "Multiple R-squared:  0.7027,\tAdjusted R-squared:  0.7003 \n",
              "F-statistic: 297.8 on 1 and 126 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the p-value is small which is a good sign with adjusted r-squared value being 0.70 meaning that 70% of variance in the dataset can be explained using the linear model as the abdominal circumference as the only predictor.\n",
        "\n",
        "------\n",
        "\n",
        "Lets create a model that includes all the features"
      ],
      "metadata": {
        "id": "6BGwg-gtfLao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = lm(data = bfData, Bodyfat ~ .)\n",
        "summary(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "x0frtodgR4On",
        "outputId": "549996bf-3140-4c1a-fc24-d3d3d3a85d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Bodyfat ~ ., data = bfData)\n",
              "\n",
              "Residuals:\n",
              "    Min      1Q  Median      3Q     Max \n",
              "-9.3767 -2.5514 -0.1723  2.6391  9.1393 \n",
              "\n",
              "Coefficients:\n",
              "              Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept) -52.553646  40.062856  -1.312   0.1922    \n",
              "Age           0.009288   0.043470   0.214   0.8312    \n",
              "Weight       -0.271016   0.243569  -1.113   0.2682    \n",
              "Height        0.258388   0.320810   0.805   0.4223    \n",
              "Neck         -0.592669   0.322125  -1.840   0.0684 .  \n",
              "Chest         0.090883   0.164738   0.552   0.5822    \n",
              "Abdo          0.995184   0.123072   8.086 7.29e-13 ***\n",
              "Hip          -0.141981   0.204533  -0.694   0.4890    \n",
              "Thigh         0.101272   0.200714   0.505   0.6148    \n",
              "Knee         -0.096682   0.325889  -0.297   0.7673    \n",
              "Ankle        -0.048017   0.507695  -0.095   0.9248    \n",
              "Bic           0.075332   0.244105   0.309   0.7582    \n",
              "Fore          0.412107   0.272144   1.514   0.1327    \n",
              "Wrist        -0.263067   0.745145  -0.353   0.7247    \n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 4.081 on 114 degrees of freedom\n",
              "Multiple R-squared:  0.7519,\tAdjusted R-squared:  0.7236 \n",
              "F-statistic: 26.57 on 13 and 114 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the adjusted r-squared has only slightly improved from 70% to 72%. But most importantly we can see that many of the variables has the p-value bigger than any threshold we may use.\n",
        "\n",
        "Therefore, we can see that id does not always have to be all the predictors in order to build the model. We have to have a methodical way of selecting the predictors in suach a way that the final model will be an optimal one.\n",
        "\n",
        "## **How can we achieve this?**\n",
        "\n",
        "### 1. Subset-Based Model Selection"
      ],
      "metadata": {
        "id": "HbBQSVcWgFMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset-based model selection using adjusted-R2 statistic (leaps package)\n",
        "# lets create a matrix of predictors and a vector of response\n",
        "X = as.matrix(bfData %>% select(-c(Bodyfat))) # matrix of covariates\n",
        "y = as.matrix(bfData %>% select('Bodyfat')) # vector of response values"
      ],
      "metadata": {
        "id": "QZWnZ6ZYR4P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building a model using adjusted-R2 statistic (leaps package)\n",
        "# names are names of predictors\n",
        "model.leaps = leaps(X, y, names = names(bfData %>% select(-c('Bodyfat'))), method = 'adjr2')"
      ],
      "metadata": {
        "id": "g5wLWV-Uh8Qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This process is going to look into the matrix of covariates and it is going to select the subsets of covariates and then evaluate the adjusted R-squared value of the model built using those subsets of covariates.\n",
        "\n",
        "From the list we can choose a model that has the best adjusted R-squared value."
      ],
      "metadata": {
        "id": "neP69pAji5e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.leaps$which"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pNEok3cijTGe",
        "outputId": "4736fd7f-436f-40c6-d45e-0a6621fde33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 121 × 13 of type lgl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Age</th><th scope=col>Weight</th><th scope=col>Height</th><th scope=col>Neck</th><th scope=col>Chest</th><th scope=col>Abdo</th><th scope=col>Hip</th><th scope=col>Thigh</th><th scope=col>Knee</th><th scope=col>Ankle</th><th scope=col>Bic</th><th scope=col>Fore</th><th scope=col>Wrist</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>1</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>1</th><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>1</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>1</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>1</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>1</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>1</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>1</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>1</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>FALSE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>TRUE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>TRUE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>10</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>10</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>TRUE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>11</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>11</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>11</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>TRUE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>11</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>11</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>11</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>TRUE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>12</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>12</th><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>12</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>12</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>12</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td>FALSE</td></tr>\n",
              "\t<tr><th scope=row>12</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>FALSE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>12</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td>FALSE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>12</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td>FALSE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>12</th><td> TRUE</td><td> TRUE</td><td>FALSE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>12</th><td> TRUE</td><td>FALSE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "\t<tr><th scope=row>13</th><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td> TRUE</td><td>TRUE</td><td> TRUE</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 121 × 13 of type lgl\n\n| <!--/--> | Age | Weight | Height | Neck | Chest | Abdo | Hip | Thigh | Knee | Ankle | Bic | Fore | Wrist |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 1 | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 1 | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 1 | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 1 | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 1 | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE |\n| 1 | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE |\n| 1 | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 1 | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE |\n| 1 | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE |\n| 2 | FALSE |  TRUE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 2 | FALSE | FALSE | FALSE |  TRUE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 2 | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 2 | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE |\n| 2 | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE |\n| 2 | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE |\n| 2 | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 2 | FALSE | FALSE |  TRUE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 2 | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE |\n| 2 | FALSE | FALSE | FALSE | FALSE |  TRUE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 3 | FALSE | FALSE | FALSE |  TRUE | FALSE |  TRUE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 3 | FALSE |  TRUE | FALSE |  TRUE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 3 | FALSE |  TRUE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE |\n| 3 | FALSE |  TRUE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE | FALSE |\n| 3 | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE |\n| 3 | FALSE | FALSE | FALSE |  TRUE | FALSE |  TRUE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE |\n| 3 | FALSE | FALSE | FALSE |  TRUE | FALSE |  TRUE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE |\n| 3 | FALSE |  TRUE | FALSE | FALSE | FALSE |  TRUE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 3 | FALSE |  TRUE |  TRUE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n| 3 | FALSE |  TRUE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE |  TRUE | FALSE | FALSE | FALSE |\n| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n| 10 | FALSE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE | FALSE | FALSE | TRUE |  TRUE |\n| 10 | FALSE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE | FALSE |  TRUE | TRUE | FALSE |\n| 10 | FALSE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE | FALSE |  TRUE | FALSE | TRUE |  TRUE |\n| 10 | FALSE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE | FALSE |  TRUE |  TRUE | TRUE | FALSE |\n| 10 | FALSE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE |  TRUE | FALSE | TRUE | FALSE |\n| 10 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE | FALSE | FALSE | FALSE | TRUE |  TRUE |\n| 10 | FALSE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE | FALSE |  TRUE | FALSE |  TRUE | TRUE |  TRUE |\n| 10 | FALSE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE | FALSE | FALSE |  TRUE |  TRUE | TRUE |  TRUE |\n| 10 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE | FALSE | FALSE | TRUE | FALSE |\n| 11 | FALSE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE | FALSE |  TRUE | TRUE |  TRUE |\n| 11 | FALSE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE | FALSE |  TRUE |  TRUE | TRUE |  TRUE |\n| 11 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE | FALSE | FALSE | TRUE |  TRUE |\n| 11 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE | FALSE | FALSE |  TRUE | TRUE |  TRUE |\n| 11 | FALSE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE |  TRUE |  TRUE | TRUE | FALSE |\n| 11 | FALSE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE |  TRUE | FALSE | TRUE |  TRUE |\n| 11 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE | FALSE |  TRUE | TRUE | FALSE |\n| 11 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE | FALSE |  TRUE | FALSE | TRUE |  TRUE |\n| 11 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE | FALSE |  TRUE |  TRUE | TRUE | FALSE |\n| 11 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE |  TRUE | FALSE | TRUE | FALSE |\n| 12 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE | FALSE |  TRUE | TRUE |  TRUE |\n| 12 | FALSE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE |  TRUE |  TRUE | TRUE |  TRUE |\n| 12 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE | FALSE |  TRUE |  TRUE | TRUE |  TRUE |\n| 12 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE |  TRUE | FALSE | TRUE |  TRUE |\n| 12 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE |  TRUE |  TRUE | TRUE | FALSE |\n| 12 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE | FALSE |  TRUE |  TRUE |  TRUE | TRUE |  TRUE |\n| 12 |  TRUE |  TRUE |  TRUE | TRUE | FALSE | TRUE |  TRUE |  TRUE |  TRUE |  TRUE |  TRUE | TRUE |  TRUE |\n| 12 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE | FALSE |  TRUE |  TRUE |  TRUE |  TRUE | TRUE |  TRUE |\n| 12 |  TRUE |  TRUE | FALSE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE |  TRUE |  TRUE | TRUE |  TRUE |\n| 12 |  TRUE | FALSE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE |  TRUE |  TRUE | TRUE |  TRUE |\n| 13 |  TRUE |  TRUE |  TRUE | TRUE |  TRUE | TRUE |  TRUE |  TRUE |  TRUE |  TRUE |  TRUE | TRUE |  TRUE |\n\n",
            "text/latex": "A matrix: 121 × 13 of type lgl\n\\begin{tabular}{r|lllllllllllll}\n  & Age & Weight & Height & Neck & Chest & Abdo & Hip & Thigh & Knee & Ankle & Bic & Fore & Wrist\\\\\n\\hline\n\t1 & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t1 & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t1 & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t1 & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t1 & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t1 & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE\\\\\n\t1 & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE\\\\\n\t1 & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t1 & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE\\\\\n\t1 & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE\\\\\n\t2 & FALSE &  TRUE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t2 & FALSE & FALSE & FALSE &  TRUE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t2 & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t2 & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE\\\\\n\t2 & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE\\\\\n\t2 & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE\\\\\n\t2 & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t2 & FALSE & FALSE &  TRUE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t2 & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE\\\\\n\t2 & FALSE & FALSE & FALSE & FALSE &  TRUE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t3 & FALSE & FALSE & FALSE &  TRUE & FALSE &  TRUE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t3 & FALSE &  TRUE & FALSE &  TRUE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t3 & FALSE &  TRUE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE\\\\\n\t3 & FALSE &  TRUE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE & FALSE\\\\\n\t3 & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE\\\\\n\t3 & FALSE & FALSE & FALSE &  TRUE & FALSE &  TRUE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE\\\\\n\t3 & FALSE & FALSE & FALSE &  TRUE & FALSE &  TRUE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE\\\\\n\t3 & FALSE &  TRUE & FALSE & FALSE & FALSE &  TRUE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t3 & FALSE &  TRUE &  TRUE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n\t3 & FALSE &  TRUE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE &  TRUE & FALSE & FALSE & FALSE\\\\\n\t⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n\t10 & FALSE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE & FALSE & FALSE & TRUE &  TRUE\\\\\n\t10 & FALSE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE & FALSE &  TRUE & TRUE & FALSE\\\\\n\t10 & FALSE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE & FALSE &  TRUE & FALSE & TRUE &  TRUE\\\\\n\t10 & FALSE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE & FALSE &  TRUE &  TRUE & TRUE & FALSE\\\\\n\t10 & FALSE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE &  TRUE & FALSE & TRUE & FALSE\\\\\n\t10 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE & FALSE & FALSE & FALSE & TRUE &  TRUE\\\\\n\t10 & FALSE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE & FALSE &  TRUE & FALSE &  TRUE & TRUE &  TRUE\\\\\n\t10 & FALSE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE & FALSE & FALSE &  TRUE &  TRUE & TRUE &  TRUE\\\\\n\t10 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE & FALSE & FALSE & TRUE & FALSE\\\\\n\t11 & FALSE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE & FALSE &  TRUE & TRUE &  TRUE\\\\\n\t11 & FALSE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE & FALSE &  TRUE &  TRUE & TRUE &  TRUE\\\\\n\t11 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE & FALSE & FALSE & TRUE &  TRUE\\\\\n\t11 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE & FALSE & FALSE &  TRUE & TRUE &  TRUE\\\\\n\t11 & FALSE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE &  TRUE &  TRUE & TRUE & FALSE\\\\\n\t11 & FALSE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE &  TRUE & FALSE & TRUE &  TRUE\\\\\n\t11 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE & FALSE &  TRUE & TRUE & FALSE\\\\\n\t11 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE & FALSE &  TRUE & FALSE & TRUE &  TRUE\\\\\n\t11 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE & FALSE &  TRUE &  TRUE & TRUE & FALSE\\\\\n\t11 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE &  TRUE & FALSE & TRUE & FALSE\\\\\n\t12 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE & FALSE &  TRUE & TRUE &  TRUE\\\\\n\t12 & FALSE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE &  TRUE &  TRUE & TRUE &  TRUE\\\\\n\t12 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE & FALSE &  TRUE &  TRUE & TRUE &  TRUE\\\\\n\t12 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE &  TRUE & FALSE & TRUE &  TRUE\\\\\n\t12 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE &  TRUE &  TRUE & TRUE & FALSE\\\\\n\t12 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE & FALSE &  TRUE &  TRUE &  TRUE & TRUE &  TRUE\\\\\n\t12 &  TRUE &  TRUE &  TRUE & TRUE & FALSE & TRUE &  TRUE &  TRUE &  TRUE &  TRUE &  TRUE & TRUE &  TRUE\\\\\n\t12 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE & FALSE &  TRUE &  TRUE &  TRUE &  TRUE & TRUE &  TRUE\\\\\n\t12 &  TRUE &  TRUE & FALSE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE &  TRUE &  TRUE & TRUE &  TRUE\\\\\n\t12 &  TRUE & FALSE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE &  TRUE &  TRUE & TRUE &  TRUE\\\\\n\t13 &  TRUE &  TRUE &  TRUE & TRUE &  TRUE & TRUE &  TRUE &  TRUE &  TRUE &  TRUE &  TRUE & TRUE &  TRUE\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   Age   Weight Height Neck  Chest Abdo  Hip   Thigh Knee  Ankle Bic   Fore \n",
              "1  FALSE FALSE  FALSE  FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "1  FALSE FALSE  FALSE  FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "1  FALSE  TRUE  FALSE  FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "1  FALSE FALSE  FALSE  FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE\n",
              "1  FALSE FALSE  FALSE  FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n",
              "1  FALSE FALSE  FALSE  FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\n",
              "1  FALSE FALSE  FALSE  FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n",
              "1  FALSE FALSE  FALSE   TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "1  FALSE FALSE  FALSE  FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "1  FALSE FALSE  FALSE  FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n",
              "2  FALSE  TRUE  FALSE  FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "2  FALSE FALSE  FALSE   TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "2  FALSE FALSE  FALSE  FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n",
              "2  FALSE FALSE  FALSE  FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "2  FALSE FALSE  FALSE  FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE\n",
              "2  FALSE FALSE  FALSE  FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE\n",
              "2  FALSE FALSE  FALSE  FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE\n",
              "2  FALSE FALSE   TRUE  FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "2  FALSE FALSE  FALSE  FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE\n",
              "2  FALSE FALSE  FALSE  FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "3  FALSE FALSE  FALSE   TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n",
              "3  FALSE  TRUE  FALSE   TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "3  FALSE  TRUE  FALSE  FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "3  FALSE  TRUE  FALSE  FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE\n",
              "3  FALSE FALSE  FALSE  FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n",
              "3  FALSE FALSE  FALSE   TRUE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE\n",
              "3  FALSE FALSE  FALSE   TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE\n",
              "3  FALSE  TRUE  FALSE  FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n",
              "3  FALSE  TRUE   TRUE  FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n",
              "3  FALSE  TRUE  FALSE  FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE\n",
              "⋮  ⋮     ⋮      ⋮      ⋮     ⋮     ⋮     ⋮     ⋮     ⋮     ⋮     ⋮     ⋮    \n",
              "10 FALSE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE FALSE FALSE TRUE \n",
              "10 FALSE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE FALSE  TRUE TRUE \n",
              "10 FALSE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE FALSE  TRUE FALSE TRUE \n",
              "10 FALSE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE FALSE  TRUE  TRUE TRUE \n",
              "10 FALSE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE  TRUE FALSE TRUE \n",
              "10  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE FALSE FALSE FALSE TRUE \n",
              "10 FALSE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE FALSE  TRUE FALSE  TRUE TRUE \n",
              "10 FALSE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE FALSE FALSE  TRUE  TRUE TRUE \n",
              "10  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE FALSE FALSE TRUE \n",
              "11 FALSE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE FALSE  TRUE TRUE \n",
              "11 FALSE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE FALSE  TRUE  TRUE TRUE \n",
              "11  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE FALSE FALSE TRUE \n",
              "11  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE FALSE FALSE  TRUE TRUE \n",
              "11 FALSE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE  TRUE  TRUE TRUE \n",
              "11 FALSE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE  TRUE FALSE TRUE \n",
              "11  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE FALSE  TRUE TRUE \n",
              "11  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE FALSE  TRUE FALSE TRUE \n",
              "11  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE FALSE  TRUE  TRUE TRUE \n",
              "11  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE  TRUE FALSE TRUE \n",
              "12  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE FALSE  TRUE TRUE \n",
              "12 FALSE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE  TRUE  TRUE TRUE \n",
              "12  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE FALSE  TRUE  TRUE TRUE \n",
              "12  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE  TRUE FALSE TRUE \n",
              "12  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE  TRUE  TRUE TRUE \n",
              "12  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE FALSE  TRUE  TRUE  TRUE TRUE \n",
              "12  TRUE  TRUE   TRUE  TRUE  FALSE TRUE   TRUE  TRUE  TRUE  TRUE  TRUE TRUE \n",
              "12  TRUE  TRUE   TRUE  TRUE   TRUE TRUE  FALSE  TRUE  TRUE  TRUE  TRUE TRUE \n",
              "12  TRUE  TRUE  FALSE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE  TRUE  TRUE TRUE \n",
              "12  TRUE FALSE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE  TRUE  TRUE TRUE \n",
              "13  TRUE  TRUE   TRUE  TRUE   TRUE TRUE   TRUE  TRUE  TRUE  TRUE  TRUE TRUE \n",
              "   Wrist\n",
              "1  FALSE\n",
              "1  FALSE\n",
              "1  FALSE\n",
              "1  FALSE\n",
              "1  FALSE\n",
              "1  FALSE\n",
              "1  FALSE\n",
              "1  FALSE\n",
              "1   TRUE\n",
              "1  FALSE\n",
              "2  FALSE\n",
              "2  FALSE\n",
              "2  FALSE\n",
              "2   TRUE\n",
              "2  FALSE\n",
              "2  FALSE\n",
              "2  FALSE\n",
              "2  FALSE\n",
              "2  FALSE\n",
              "2  FALSE\n",
              "3  FALSE\n",
              "3  FALSE\n",
              "3   TRUE\n",
              "3  FALSE\n",
              "3   TRUE\n",
              "3  FALSE\n",
              "3  FALSE\n",
              "3  FALSE\n",
              "3  FALSE\n",
              "3  FALSE\n",
              "⋮  ⋮    \n",
              "10  TRUE\n",
              "10 FALSE\n",
              "10  TRUE\n",
              "10 FALSE\n",
              "10 FALSE\n",
              "10  TRUE\n",
              "10  TRUE\n",
              "10  TRUE\n",
              "10 FALSE\n",
              "11  TRUE\n",
              "11  TRUE\n",
              "11  TRUE\n",
              "11  TRUE\n",
              "11 FALSE\n",
              "11  TRUE\n",
              "11 FALSE\n",
              "11  TRUE\n",
              "11 FALSE\n",
              "11 FALSE\n",
              "12  TRUE\n",
              "12  TRUE\n",
              "12  TRUE\n",
              "12  TRUE\n",
              "12 FALSE\n",
              "12  TRUE\n",
              "12  TRUE\n",
              "12  TRUE\n",
              "12  TRUE\n",
              "12  TRUE\n",
              "13  TRUE"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first model has only one predictor. It uses Abdo. The second model uses Chese as the predictor variable and so on.\n",
        "\n",
        "So the model is building all these subsets and evaluating the adjusted R-squared."
      ],
      "metadata": {
        "id": "pOa-wP1-kIOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.leaps$adjr2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "ACkJ8f16jTVC",
        "outputId": "19b34d04-8c8b-46cb-c22f-e41fb6a88ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0.700310253006608</li><li>0.540938477458351</li><li>0.433152447754517</li><li>0.388742425784025</li><li>0.267303376277467</li><li>0.235564897314017</li><li>0.231711675269844</li><li>0.209799502121303</li><li>0.169940307919945</li><li>0.122351214791594</li><li>0.728316619879485</li><li>0.723404221145449</li><li>0.721848554441062</li><li>0.71572052332253</li><li>0.713809068861376</li><li>0.712976415488554</li><li>0.710459845387956</li><li>0.706469881037217</li><li>0.705006303398263</li><li>0.701535563030062</li><li>0.735567544055558</li><li>0.733429493052629</li><li>0.730605962453178</li><li>0.729023433338222</li><li>0.728714493640472</li><li>0.728579238308404</li><li>0.728287168939205</li><li>0.727561229402641</li><li>0.72743490961716</li><li>0.726605407227451</li><li>0.738319554087453</li><li>0.737280711916425</li><li>0.734759324551173</li><li>0.734513708471018</li><li>0.734463176535459</li><li>0.734420118469558</li><li>0.734392766412254</li><li>0.733755239961389</li><li>0.733714482065297</li><li>0.733485935473433</li><li>0.738458859000732</li><li>0.737407882360978</li><li>0.737312558791489</li><li>0.737188372937151</li><li>0.73714872798586</li><li>0.736790292878327</li><li>0.736471045814916</li><li>0.736436903462744</li><li>0.736377705054487</li><li>0.736314364452931</li><li>0.737308550906163</li><li>0.737017540899872</li><li>0.737006912580236</li><li>0.73687460597952</li><li>0.736596816990586</li><li>0.736486731382761</li><li>0.736462437083208</li><li>0.736429645000305</li><li>0.736352658484333</li><li>0.736074429524315</li><li>0.735509788538643</li><li>0.735492279962473</li><li>0.735430824009388</li><li>0.735426143775596</li><li>0.735375222733209</li><li>0.735333240198317</li><li>0.735294461436716</li><li>0.735285425943801</li><li>0.735276616295436</li><li>0.735256289324908</li><li>0.734178552595616</li><li>0.733922881823311</li><li>0.733879111328761</li><li>0.733791010054196</li><li>0.733690826075741</li><li>0.733607063906153</li><li>0.733554502140872</li><li>0.73352246320845</li><li>0.733514686396473</li><li>0.733511393171971</li><li>0.732318629652026</li><li>0.7322609933166</li><li>0.73224418645626</li><li>0.732234030600969</li><li>0.732219759373987</li><li>0.731931935579583</li><li>0.731788162932747</li><li>0.731783515083548</li><li>0.731768107612252</li><li>0.731734180905142</li><li>0.73031806805057</li><li>0.730233641974402</li><li>0.730232471781178</li><li>0.730193506442409</li><li>0.730158702138716</li><li>0.730133568383373</li><li>0.730065816961791</li><li>0.730028279437655</li><li>0.729980732558224</li><li>0.729975295480408</li><li>0.728183304811775</li><li>0.728080137398754</li><li>0.72803216583055</li><li>0.728028526242699</li><li>0.728008517841775</li><li>0.727992710862</li><li>0.727925572019501</li><li>0.727902384829255</li><li>0.727832765723182</li><li>0.727827457341174</li><li>0.725940876652108</li><li>0.725852639035552</li><li>0.725750806696893</li><li>0.725733446128524</li><li>0.725662768578506</li><li>0.725350404120551</li><li>0.72523076125155</li><li>0.724804036175297</li><li>0.724402985508549</li><li>0.722986251941865</li><li>0.723558540131492</li></ol>\n"
            ],
            "text/markdown": "1. 0.700310253006608\n2. 0.540938477458351\n3. 0.433152447754517\n4. 0.388742425784025\n5. 0.267303376277467\n6. 0.235564897314017\n7. 0.231711675269844\n8. 0.209799502121303\n9. 0.169940307919945\n10. 0.122351214791594\n11. 0.728316619879485\n12. 0.723404221145449\n13. 0.721848554441062\n14. 0.71572052332253\n15. 0.713809068861376\n16. 0.712976415488554\n17. 0.710459845387956\n18. 0.706469881037217\n19. 0.705006303398263\n20. 0.701535563030062\n21. 0.735567544055558\n22. 0.733429493052629\n23. 0.730605962453178\n24. 0.729023433338222\n25. 0.728714493640472\n26. 0.728579238308404\n27. 0.728287168939205\n28. 0.727561229402641\n29. 0.72743490961716\n30. 0.726605407227451\n31. 0.738319554087453\n32. 0.737280711916425\n33. 0.734759324551173\n34. 0.734513708471018\n35. 0.734463176535459\n36. 0.734420118469558\n37. 0.734392766412254\n38. 0.733755239961389\n39. 0.733714482065297\n40. 0.733485935473433\n41. 0.738458859000732\n42. 0.737407882360978\n43. 0.737312558791489\n44. 0.737188372937151\n45. 0.73714872798586\n46. 0.736790292878327\n47. 0.736471045814916\n48. 0.736436903462744\n49. 0.736377705054487\n50. 0.736314364452931\n51. 0.737308550906163\n52. 0.737017540899872\n53. 0.737006912580236\n54. 0.73687460597952\n55. 0.736596816990586\n56. 0.736486731382761\n57. 0.736462437083208\n58. 0.736429645000305\n59. 0.736352658484333\n60. 0.736074429524315\n61. 0.735509788538643\n62. 0.735492279962473\n63. 0.735430824009388\n64. 0.735426143775596\n65. 0.735375222733209\n66. 0.735333240198317\n67. 0.735294461436716\n68. 0.735285425943801\n69. 0.735276616295436\n70. 0.735256289324908\n71. 0.734178552595616\n72. 0.733922881823311\n73. 0.733879111328761\n74. 0.733791010054196\n75. 0.733690826075741\n76. 0.733607063906153\n77. 0.733554502140872\n78. 0.73352246320845\n79. 0.733514686396473\n80. 0.733511393171971\n81. 0.732318629652026\n82. 0.7322609933166\n83. 0.73224418645626\n84. 0.732234030600969\n85. 0.732219759373987\n86. 0.731931935579583\n87. 0.731788162932747\n88. 0.731783515083548\n89. 0.731768107612252\n90. 0.731734180905142\n91. 0.73031806805057\n92. 0.730233641974402\n93. 0.730232471781178\n94. 0.730193506442409\n95. 0.730158702138716\n96. 0.730133568383373\n97. 0.730065816961791\n98. 0.730028279437655\n99. 0.729980732558224\n100. 0.729975295480408\n101. 0.728183304811775\n102. 0.728080137398754\n103. 0.72803216583055\n104. 0.728028526242699\n105. 0.728008517841775\n106. 0.727992710862\n107. 0.727925572019501\n108. 0.727902384829255\n109. 0.727832765723182\n110. 0.727827457341174\n111. 0.725940876652108\n112. 0.725852639035552\n113. 0.725750806696893\n114. 0.725733446128524\n115. 0.725662768578506\n116. 0.725350404120551\n117. 0.72523076125155\n118. 0.724804036175297\n119. 0.724402985508549\n120. 0.722986251941865\n121. 0.723558540131492\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 0.700310253006608\n\\item 0.540938477458351\n\\item 0.433152447754517\n\\item 0.388742425784025\n\\item 0.267303376277467\n\\item 0.235564897314017\n\\item 0.231711675269844\n\\item 0.209799502121303\n\\item 0.169940307919945\n\\item 0.122351214791594\n\\item 0.728316619879485\n\\item 0.723404221145449\n\\item 0.721848554441062\n\\item 0.71572052332253\n\\item 0.713809068861376\n\\item 0.712976415488554\n\\item 0.710459845387956\n\\item 0.706469881037217\n\\item 0.705006303398263\n\\item 0.701535563030062\n\\item 0.735567544055558\n\\item 0.733429493052629\n\\item 0.730605962453178\n\\item 0.729023433338222\n\\item 0.728714493640472\n\\item 0.728579238308404\n\\item 0.728287168939205\n\\item 0.727561229402641\n\\item 0.72743490961716\n\\item 0.726605407227451\n\\item 0.738319554087453\n\\item 0.737280711916425\n\\item 0.734759324551173\n\\item 0.734513708471018\n\\item 0.734463176535459\n\\item 0.734420118469558\n\\item 0.734392766412254\n\\item 0.733755239961389\n\\item 0.733714482065297\n\\item 0.733485935473433\n\\item 0.738458859000732\n\\item 0.737407882360978\n\\item 0.737312558791489\n\\item 0.737188372937151\n\\item 0.73714872798586\n\\item 0.736790292878327\n\\item 0.736471045814916\n\\item 0.736436903462744\n\\item 0.736377705054487\n\\item 0.736314364452931\n\\item 0.737308550906163\n\\item 0.737017540899872\n\\item 0.737006912580236\n\\item 0.73687460597952\n\\item 0.736596816990586\n\\item 0.736486731382761\n\\item 0.736462437083208\n\\item 0.736429645000305\n\\item 0.736352658484333\n\\item 0.736074429524315\n\\item 0.735509788538643\n\\item 0.735492279962473\n\\item 0.735430824009388\n\\item 0.735426143775596\n\\item 0.735375222733209\n\\item 0.735333240198317\n\\item 0.735294461436716\n\\item 0.735285425943801\n\\item 0.735276616295436\n\\item 0.735256289324908\n\\item 0.734178552595616\n\\item 0.733922881823311\n\\item 0.733879111328761\n\\item 0.733791010054196\n\\item 0.733690826075741\n\\item 0.733607063906153\n\\item 0.733554502140872\n\\item 0.73352246320845\n\\item 0.733514686396473\n\\item 0.733511393171971\n\\item 0.732318629652026\n\\item 0.7322609933166\n\\item 0.73224418645626\n\\item 0.732234030600969\n\\item 0.732219759373987\n\\item 0.731931935579583\n\\item 0.731788162932747\n\\item 0.731783515083548\n\\item 0.731768107612252\n\\item 0.731734180905142\n\\item 0.73031806805057\n\\item 0.730233641974402\n\\item 0.730232471781178\n\\item 0.730193506442409\n\\item 0.730158702138716\n\\item 0.730133568383373\n\\item 0.730065816961791\n\\item 0.730028279437655\n\\item 0.729980732558224\n\\item 0.729975295480408\n\\item 0.728183304811775\n\\item 0.728080137398754\n\\item 0.72803216583055\n\\item 0.728028526242699\n\\item 0.728008517841775\n\\item 0.727992710862\n\\item 0.727925572019501\n\\item 0.727902384829255\n\\item 0.727832765723182\n\\item 0.727827457341174\n\\item 0.725940876652108\n\\item 0.725852639035552\n\\item 0.725750806696893\n\\item 0.725733446128524\n\\item 0.725662768578506\n\\item 0.725350404120551\n\\item 0.72523076125155\n\\item 0.724804036175297\n\\item 0.724402985508549\n\\item 0.722986251941865\n\\item 0.723558540131492\n\\end{enumerate*}\n",
            "text/plain": [
              "  [1] 0.7003103 0.5409385 0.4331524 0.3887424 0.2673034 0.2355649 0.2317117\n",
              "  [8] 0.2097995 0.1699403 0.1223512 0.7283166 0.7234042 0.7218486 0.7157205\n",
              " [15] 0.7138091 0.7129764 0.7104598 0.7064699 0.7050063 0.7015356 0.7355675\n",
              " [22] 0.7334295 0.7306060 0.7290234 0.7287145 0.7285792 0.7282872 0.7275612\n",
              " [29] 0.7274349 0.7266054 0.7383196 0.7372807 0.7347593 0.7345137 0.7344632\n",
              " [36] 0.7344201 0.7343928 0.7337552 0.7337145 0.7334859 0.7384589 0.7374079\n",
              " [43] 0.7373126 0.7371884 0.7371487 0.7367903 0.7364710 0.7364369 0.7363777\n",
              " [50] 0.7363144 0.7373086 0.7370175 0.7370069 0.7368746 0.7365968 0.7364867\n",
              " [57] 0.7364624 0.7364296 0.7363527 0.7360744 0.7355098 0.7354923 0.7354308\n",
              " [64] 0.7354261 0.7353752 0.7353332 0.7352945 0.7352854 0.7352766 0.7352563\n",
              " [71] 0.7341786 0.7339229 0.7338791 0.7337910 0.7336908 0.7336071 0.7335545\n",
              " [78] 0.7335225 0.7335147 0.7335114 0.7323186 0.7322610 0.7322442 0.7322340\n",
              " [85] 0.7322198 0.7319319 0.7317882 0.7317835 0.7317681 0.7317342 0.7303181\n",
              " [92] 0.7302336 0.7302325 0.7301935 0.7301587 0.7301336 0.7300658 0.7300283\n",
              " [99] 0.7299807 0.7299753 0.7281833 0.7280801 0.7280322 0.7280285 0.7280085\n",
              "[106] 0.7279927 0.7279256 0.7279024 0.7278328 0.7278275 0.7259409 0.7258526\n",
              "[113] 0.7257508 0.7257334 0.7256628 0.7253504 0.7252308 0.7248040 0.7244030\n",
              "[120] 0.7229863 0.7235585"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Forward Stepwise Regression**\n",
        "\n",
        "### Forward stepwise selection using BIC"
      ],
      "metadata": {
        "id": "AY_jKPn_lE89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward stepwise selection using BIC\n",
        "# Intercept-only model\n",
        "model.lower = lm(data = bfData, Bodyfat ~ 1)\n",
        "# Full model\n",
        "model.upper = lm(data = bfData, Bodyfat ~ .)\n",
        "model.step = step(model.lower, scope = list(lower = model.lower, upper = model.upper), direction = 'forward', k = log(128))\n",
        "# k is the multiple of the number of degrees of freedom used for the penalty term which is log(n) for BIC and 2 for AIC\n",
        "summary(model.step)\n",
        "round(summary(model.step)$coef, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vp7UaBc1jT8M",
        "outputId": "d88ccdd4-0252-4213-fb0b-4eab492de3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start:  AIC=528.45\n",
            "Bodyfat ~ 1\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "+ Abdo    1    5376.2 2274.9 378.05\n",
            "+ Chest   1    4166.5 3484.7 432.63\n",
            "+ Weight  1    3348.3 4302.9 459.63\n",
            "+ Hip     1    3011.2 4640.0 469.28\n",
            "+ Thigh   1    2089.3 5561.8 492.48\n",
            "+ Bic     1    1848.4 5802.8 497.90\n",
            "+ Knee    1    1819.1 5832.0 498.55\n",
            "+ Neck    1    1652.8 5998.3 502.15\n",
            "+ Wrist   1    1350.2 6300.9 508.45\n",
            "+ Ankle   1     989.0 6662.2 515.58\n",
            "+ Fore    1     886.5 6764.7 517.54\n",
            "+ Age     1     495.1 7156.1 524.74\n",
            "<none>                7651.2 528.45\n",
            "+ Height  1     175.3 7475.8 530.33\n",
            "\n",
            "Step:  AIC=378.05\n",
            "Bodyfat ~ Abdo\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "+ Weight  1   228.962 2046.0 369.32\n",
            "+ Neck    1   191.968 2082.9 371.61\n",
            "+ Hip     1   180.253 2094.7 372.33\n",
            "+ Wrist   1   134.105 2140.8 375.12\n",
            "+ Ankle   1   119.710 2155.2 375.98\n",
            "+ Knee    1   113.440 2161.5 376.35\n",
            "+ Thigh   1    94.488 2180.4 377.47\n",
            "<none>                2274.9 378.05\n",
            "+ Height  1    64.441 2210.5 379.22\n",
            "+ Bic     1    53.419 2221.5 379.86\n",
            "+ Chest   1    27.282 2247.6 381.35\n",
            "+ Age     1    20.550 2254.4 381.74\n",
            "+ Fore    1    15.172 2259.8 382.04\n",
            "\n",
            "Step:  AIC=369.32\n",
            "Bodyfat ~ Abdo + Weight\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "<none>                2046.0 369.32\n",
            "+ Neck    1    54.563 1991.4 370.71\n",
            "+ Wrist   1    33.470 2012.5 372.06\n",
            "+ Fore    1    21.648 2024.3 372.81\n",
            "+ Hip     1    10.725 2035.2 373.50\n",
            "+ Height  1     9.781 2036.2 373.56\n",
            "+ Ankle   1     3.584 2042.4 373.95\n",
            "+ Chest   1     2.967 2043.0 373.99\n",
            "+ Age     1     2.596 2043.4 374.01\n",
            "+ Bic     1     2.257 2043.7 374.03\n",
            "+ Knee    1     1.891 2044.1 374.05\n",
            "+ Thigh   1     0.161 2045.8 374.16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Bodyfat ~ Abdo + Weight, data = bfData)\n",
              "\n",
              "Residuals:\n",
              "    Min      1Q  Median      3Q     Max \n",
              "-9.1441 -2.5621 -0.0781  2.9580  9.0413 \n",
              "\n",
              "Coefficients:\n",
              "             Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept) -47.99121    3.69071  -13.00  < 2e-16 ***\n",
              "Abdo          0.93880    0.07995   11.74  < 2e-16 ***\n",
              "Weight       -0.24257    0.06486   -3.74 0.000279 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 4.046 on 125 degrees of freedom\n",
              "Multiple R-squared:  0.7326,\tAdjusted R-squared:  0.7283 \n",
              "F-statistic: 171.2 on 2 and 125 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 3 × 4 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>(Intercept)</th><td>-47.991</td><td>3.691</td><td>-13.003</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>Abdo</th><td>  0.939</td><td>0.080</td><td> 11.743</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>Weight</th><td> -0.243</td><td>0.065</td><td> -3.740</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 3 × 4 of type dbl\n\n| <!--/--> | Estimate | Std. Error | t value | Pr(&gt;|t|) |\n|---|---|---|---|---|\n| (Intercept) | -47.991 | 3.691 | -13.003 | 0 |\n| Abdo |   0.939 | 0.080 |  11.743 | 0 |\n| Weight |  -0.243 | 0.065 |  -3.740 | 0 |\n\n",
            "text/latex": "A matrix: 3 × 4 of type dbl\n\\begin{tabular}{r|llll}\n  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n\\hline\n\t(Intercept) & -47.991 & 3.691 & -13.003 & 0\\\\\n\tAbdo &   0.939 & 0.080 &  11.743 & 0\\\\\n\tWeight &  -0.243 & 0.065 &  -3.740 & 0\\\\\n\\end{tabular}\n",
            "text/plain": [
              "            Estimate Std. Error t value Pr(>|t|)\n",
              "(Intercept) -47.991  3.691      -13.003 0       \n",
              "Abdo          0.939  0.080       11.743 0       \n",
              "Weight       -0.243  0.065       -3.740 0       "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we get the best model. It shows that abdomen circumference and weight are the only important predictors for predicting the far percentange with adjusted r-squared value being 72.8% approximately.\n",
        "\n",
        "### Forward stepwise selection using AIC"
      ],
      "metadata": {
        "id": "t5iv9a-vm193"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward stepwise selection using AIC\n",
        "# Intercept-only model\n",
        "model.lower = lm(data = bfData, Bodyfat ~ 1)\n",
        "# Full model\n",
        "model.upper = lm(data = bfData, Bodyfat ~ .)\n",
        "model.step = step(model.lower, scope = list(lower = model.lower, upper = model.upper), direction = 'forward', k = 2)\n",
        "# k is the multiple of the number of degrees of freedom used for the penalty which is log(n) for BIC and 2 for AIC\n",
        "summary(model.step)\n",
        "round(summary(model.step)$coef, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cwly_qbclcyy",
        "outputId": "e4d306d3-40f3-4412-f0ba-0a276c9dcd6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start:  AIC=525.59\n",
            "Bodyfat ~ 1\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "+ Abdo    1    5376.2 2274.9 372.34\n",
            "+ Chest   1    4166.5 3484.7 426.93\n",
            "+ Weight  1    3348.3 4302.9 453.92\n",
            "+ Hip     1    3011.2 4640.0 463.58\n",
            "+ Thigh   1    2089.3 5561.8 486.77\n",
            "+ Bic     1    1848.4 5802.8 492.20\n",
            "+ Knee    1    1819.1 5832.0 492.84\n",
            "+ Neck    1    1652.8 5998.3 496.44\n",
            "+ Wrist   1    1350.2 6300.9 502.74\n",
            "+ Ankle   1     989.0 6662.2 509.88\n",
            "+ Fore    1     886.5 6764.7 511.83\n",
            "+ Age     1     495.1 7156.1 519.03\n",
            "+ Height  1     175.3 7475.8 524.63\n",
            "<none>                7651.2 525.59\n",
            "\n",
            "Step:  AIC=372.34\n",
            "Bodyfat ~ Abdo\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "+ Weight  1   228.962 2046.0 360.76\n",
            "+ Neck    1   191.968 2082.9 363.06\n",
            "+ Hip     1   180.253 2094.7 363.78\n",
            "+ Wrist   1   134.105 2140.8 366.56\n",
            "+ Ankle   1   119.710 2155.2 367.42\n",
            "+ Knee    1   113.440 2161.5 367.79\n",
            "+ Thigh   1    94.488 2180.4 368.91\n",
            "+ Height  1    64.441 2210.5 370.66\n",
            "+ Bic     1    53.419 2221.5 371.30\n",
            "<none>                2274.9 372.34\n",
            "+ Chest   1    27.282 2247.6 372.80\n",
            "+ Age     1    20.550 2254.4 373.18\n",
            "+ Fore    1    15.172 2259.8 373.49\n",
            "\n",
            "Step:  AIC=360.76\n",
            "Bodyfat ~ Abdo + Weight\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "+ Neck    1    54.563 1991.4 359.30\n",
            "+ Wrist   1    33.470 2012.5 360.65\n",
            "<none>                2046.0 360.76\n",
            "+ Fore    1    21.648 2024.3 361.40\n",
            "+ Hip     1    10.725 2035.2 362.09\n",
            "+ Height  1     9.781 2036.2 362.15\n",
            "+ Ankle   1     3.584 2042.4 362.54\n",
            "+ Chest   1     2.967 2043.0 362.58\n",
            "+ Age     1     2.596 2043.4 362.60\n",
            "+ Bic     1     2.257 2043.7 362.62\n",
            "+ Knee    1     1.891 2044.1 362.65\n",
            "+ Thigh   1     0.161 2045.8 362.75\n",
            "\n",
            "Step:  AIC=359.3\n",
            "Bodyfat ~ Abdo + Weight + Neck\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "+ Fore    1    52.296 1939.1 357.90\n",
            "<none>                1991.4 359.30\n",
            "+ Hip     1    24.094 1967.3 359.75\n",
            "+ Bic     1     9.256 1982.1 360.71\n",
            "+ Chest   1     7.046 1984.3 360.85\n",
            "+ Wrist   1     6.772 1984.6 360.87\n",
            "+ Ankle   1     5.096 1986.3 360.98\n",
            "+ Knee    1     3.707 1987.7 361.07\n",
            "+ Height  1     2.231 1989.2 361.16\n",
            "+ Thigh   1     0.423 1991.0 361.28\n",
            "+ Age     1     0.010 1991.4 361.30\n",
            "\n",
            "Step:  AIC=357.9\n",
            "Bodyfat ~ Abdo + Weight + Neck + Fore\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "<none>                1939.1 357.90\n",
            "+ Hip     1   16.7889 1922.3 358.78\n",
            "+ Height  1    9.0643 1930.0 359.30\n",
            "+ Wrist   1    8.3637 1930.7 359.34\n",
            "+ Ankle   1    7.4509 1931.7 359.40\n",
            "+ Chest   1    4.5251 1934.6 359.60\n",
            "+ Knee    1    1.4926 1937.6 359.80\n",
            "+ Thigh   1    1.0270 1938.1 359.83\n",
            "+ Bic     1    0.3077 1938.8 359.88\n",
            "+ Age     1    0.2046 1938.9 359.88\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Bodyfat ~ Abdo + Weight + Neck + Fore, data = bfData)\n",
              "\n",
              "Residuals:\n",
              "    Min      1Q  Median      3Q     Max \n",
              "-9.1637 -2.8476  0.0877  2.7522  8.3342 \n",
              "\n",
              "Coefficients:\n",
              "             Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept) -41.88325    8.30967  -5.040 1.62e-06 ***\n",
              "Abdo          0.98046    0.08146  12.036  < 2e-16 ***\n",
              "Weight       -0.22932    0.07868  -2.915  0.00423 ** \n",
              "Neck         -0.61856    0.26606  -2.325  0.02172 *  \n",
              "Fore          0.43409    0.23834   1.821  0.07099 .  \n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 3.971 on 123 degrees of freedom\n",
              "Multiple R-squared:  0.7466,\tAdjusted R-squared:  0.7383 \n",
              "F-statistic: 90.58 on 4 and 123 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 5 × 4 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>(Intercept)</th><td>-41.883</td><td>8.310</td><td>-5.040</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>Abdo</th><td>  0.980</td><td>0.081</td><td>12.036</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>Weight</th><td> -0.229</td><td>0.079</td><td>-2.915</td><td>0.004</td></tr>\n",
              "\t<tr><th scope=row>Neck</th><td> -0.619</td><td>0.266</td><td>-2.325</td><td>0.022</td></tr>\n",
              "\t<tr><th scope=row>Fore</th><td>  0.434</td><td>0.238</td><td> 1.821</td><td>0.071</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 5 × 4 of type dbl\n\n| <!--/--> | Estimate | Std. Error | t value | Pr(&gt;|t|) |\n|---|---|---|---|---|\n| (Intercept) | -41.883 | 8.310 | -5.040 | 0.000 |\n| Abdo |   0.980 | 0.081 | 12.036 | 0.000 |\n| Weight |  -0.229 | 0.079 | -2.915 | 0.004 |\n| Neck |  -0.619 | 0.266 | -2.325 | 0.022 |\n| Fore |   0.434 | 0.238 |  1.821 | 0.071 |\n\n",
            "text/latex": "A matrix: 5 × 4 of type dbl\n\\begin{tabular}{r|llll}\n  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n\\hline\n\t(Intercept) & -41.883 & 8.310 & -5.040 & 0.000\\\\\n\tAbdo &   0.980 & 0.081 & 12.036 & 0.000\\\\\n\tWeight &  -0.229 & 0.079 & -2.915 & 0.004\\\\\n\tNeck &  -0.619 & 0.266 & -2.325 & 0.022\\\\\n\tFore &   0.434 & 0.238 &  1.821 & 0.071\\\\\n\\end{tabular}\n",
            "text/plain": [
              "            Estimate Std. Error t value Pr(>|t|)\n",
              "(Intercept) -41.883  8.310      -5.040  0.000   \n",
              "Abdo          0.980  0.081      12.036  0.000   \n",
              "Weight       -0.229  0.079      -2.915  0.004   \n",
              "Neck         -0.619  0.266      -2.325  0.022   \n",
              "Fore          0.434  0.238       1.821  0.071   "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that this approach gives us 4 predictors with slightly better adjusted r-squared value at 73.83% approximately.\n",
        "\n",
        "---\n",
        "\n",
        "Now if we have to decide which model to choose the model based on adjusted r-squared we mat choose this model but there are other things to consider too. We also have to look at the interpretability of the model and also the complexity of the model.\n",
        "\n",
        "So, putting into prespective,\n",
        "- we can see that this model is uisng predictors like forehead circumference, neck circumference that probably are not very interpretable.\n",
        "- Its also complex because it's using additional predictors.\n",
        "\n",
        "Therefore, in this scenario, choosing the earlier model with just 2 covariates is the best decision.\n",
        "\n",
        "-----\n",
        "\n",
        "# Backward Stepwise Selection"
      ],
      "metadata": {
        "id": "5lF8I7lRob2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward stepwise selection using BIC\n",
        "# Intercept-only model\n",
        "model.lower = lm(data = bfData, Bodyfat ~ 1)\n",
        "# Full model\n",
        "model.upper = lm(data = bfData, Bodyfat ~ .)\n",
        "model.step = step(model.upper, scope = list(lower = model.lower, upper = model.upper), direction = 'backward', k = log(128))\n",
        "summary(model.step)\n",
        "round(summary(model.step)$coef, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U21ZTsxuqIzX",
        "outputId": "018812b4-b2d4-4bff-8180-b4e5ff920240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start:  AIC=413.12\n",
            "Bodyfat ~ Age + Weight + Height + Neck + Chest + Abdo + Hip + \n",
            "    Thigh + Knee + Ankle + Bic + Fore + Wrist\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Ankle   1      0.15 1898.7 408.28\n",
            "- Age     1      0.76 1899.3 408.32\n",
            "- Knee    1      1.47 1900.1 408.37\n",
            "- Bic     1      1.59 1900.2 408.38\n",
            "- Wrist   1      2.08 1900.7 408.41\n",
            "- Thigh   1      4.24 1902.8 408.56\n",
            "- Chest   1      5.07 1903.7 408.61\n",
            "- Hip     1      8.03 1906.6 408.81\n",
            "- Height  1     10.80 1909.4 409.00\n",
            "- Weight  1     20.62 1919.2 409.65\n",
            "- Fore    1     38.19 1936.8 410.82\n",
            "- Neck    1     56.38 1955.0 412.02\n",
            "<none>                1898.6 413.12\n",
            "- Abdo    1   1088.97 2987.6 466.30\n",
            "\n",
            "Step:  AIC=408.28\n",
            "Bodyfat ~ Age + Weight + Height + Neck + Chest + Abdo + Hip + \n",
            "    Thigh + Knee + Bic + Fore + Wrist\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Age     1      0.84 1899.6 403.49\n",
            "- Bic     1      1.90 1900.6 403.56\n",
            "- Knee    1      1.92 1900.7 403.56\n",
            "- Wrist   1      2.64 1901.4 403.61\n",
            "- Thigh   1      4.15 1902.9 403.71\n",
            "- Chest   1      5.55 1904.3 403.80\n",
            "- Hip     1      7.93 1906.7 403.96\n",
            "- Height  1     11.90 1910.6 404.23\n",
            "- Weight  1     23.59 1922.3 405.01\n",
            "- Fore    1     38.15 1936.9 405.98\n",
            "- Neck    1     57.25 1956.0 407.23\n",
            "<none>                1898.7 408.28\n",
            "- Abdo    1   1125.31 3024.1 463.00\n",
            "\n",
            "Step:  AIC=403.49\n",
            "Bodyfat ~ Weight + Height + Neck + Chest + Abdo + Hip + Thigh + \n",
            "    Knee + Bic + Fore + Wrist\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Knee    1      1.33 1900.9 398.72\n",
            "- Bic     1      1.92 1901.5 398.76\n",
            "- Wrist   1      1.93 1901.5 398.76\n",
            "- Thigh   1      3.37 1903.0 398.86\n",
            "- Chest   1      6.39 1906.0 399.06\n",
            "- Hip     1      8.14 1907.7 399.18\n",
            "- Height  1     12.16 1911.7 399.45\n",
            "- Weight  1     27.13 1926.7 400.45\n",
            "- Fore    1     37.85 1937.4 401.16\n",
            "- Neck    1     56.57 1956.1 402.39\n",
            "<none>                1899.6 403.49\n",
            "- Abdo    1   1346.09 3245.7 467.20\n",
            "\n",
            "Step:  AIC=398.72\n",
            "Bodyfat ~ Weight + Height + Neck + Chest + Abdo + Hip + Thigh + \n",
            "    Bic + Fore + Wrist\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Bic     1      2.03 1902.9 394.01\n",
            "- Thigh   1      2.63 1903.5 394.05\n",
            "- Wrist   1      2.73 1903.6 394.06\n",
            "- Chest   1      7.05 1908.0 394.35\n",
            "- Hip     1      7.62 1908.5 394.38\n",
            "- Height  1     11.23 1912.1 394.63\n",
            "- Weight  1     30.51 1931.4 395.91\n",
            "- Fore    1     39.05 1940.0 396.47\n",
            "- Neck    1     55.47 1956.4 397.55\n",
            "<none>                1900.9 398.72\n",
            "- Abdo    1   1345.48 3246.4 462.38\n",
            "\n",
            "Step:  AIC=394.01\n",
            "Bodyfat ~ Weight + Height + Neck + Chest + Abdo + Hip + Thigh + \n",
            "    Fore + Wrist\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Wrist   1      2.79 1905.7 389.34\n",
            "- Thigh   1      4.63 1907.6 389.47\n",
            "- Hip     1      7.50 1910.4 389.66\n",
            "- Chest   1      7.55 1910.5 389.66\n",
            "- Height  1     10.21 1913.1 389.84\n",
            "- Weight  1     29.27 1932.2 391.11\n",
            "- Fore    1     50.40 1953.3 392.50\n",
            "- Neck    1     54.04 1957.0 392.74\n",
            "<none>                1902.9 394.01\n",
            "- Abdo    1   1353.15 3256.1 457.91\n",
            "\n",
            "Step:  AIC=389.34\n",
            "Bodyfat ~ Weight + Height + Neck + Chest + Abdo + Hip + Thigh + \n",
            "    Fore\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Thigh   1      7.00 1912.7 384.96\n",
            "- Hip     1      8.01 1913.7 385.03\n",
            "- Chest   1      9.29 1915.0 385.11\n",
            "- Height  1     13.86 1919.6 385.42\n",
            "- Weight  1     36.34 1942.1 386.91\n",
            "- Fore    1     50.12 1955.8 387.81\n",
            "<none>                1905.7 389.34\n",
            "- Neck    1     79.05 1984.8 389.69\n",
            "- Abdo    1   1372.77 3278.5 453.93\n",
            "\n",
            "Step:  AIC=384.96\n",
            "Bodyfat ~ Weight + Height + Neck + Chest + Abdo + Hip + Fore\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Hip     1      4.42 1917.1 380.40\n",
            "- Chest   1      5.38 1918.1 380.47\n",
            "- Height  1      8.62 1921.3 380.68\n",
            "- Weight  1     29.49 1942.2 382.07\n",
            "- Fore    1     51.53 1964.3 383.51\n",
            "<none>                1912.7 384.96\n",
            "- Neck    1     80.80 1993.5 385.40\n",
            "- Abdo    1   1372.41 3285.1 449.34\n",
            "\n",
            "Step:  AIC=380.4\n",
            "Bodyfat ~ Weight + Height + Neck + Chest + Abdo + Fore\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Chest   1     12.90 1930.0 376.41\n",
            "- Height  1     17.44 1934.6 376.71\n",
            "- Fore    1     59.51 1976.6 379.46\n",
            "<none>                1917.1 380.40\n",
            "- Neck    1     76.42 1993.6 380.55\n",
            "- Weight  1    117.40 2034.5 383.16\n",
            "- Abdo    1   1370.48 3287.6 444.59\n",
            "\n",
            "Step:  AIC=376.41\n",
            "Bodyfat ~ Weight + Height + Neck + Abdo + Fore\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Height  1      9.06 1939.1 372.16\n",
            "- Fore    1     59.13 1989.2 375.42\n",
            "- Neck    1     74.35 2004.4 376.40\n",
            "<none>                1930.0 376.41\n",
            "- Weight  1    107.93 2038.0 378.52\n",
            "- Abdo    1   1679.52 3609.6 451.69\n",
            "\n",
            "Step:  AIC=372.16\n",
            "Bodyfat ~ Weight + Neck + Abdo + Fore\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Fore    1     52.30 1991.4 370.71\n",
            "<none>                1939.1 372.16\n",
            "- Neck    1     85.21 2024.3 372.81\n",
            "- Weight  1    133.93 2073.0 375.85\n",
            "- Abdo    1   2283.87 4223.0 466.93\n",
            "\n",
            "Step:  AIC=370.71\n",
            "Bodyfat ~ Weight + Neck + Abdo\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Neck    1     54.56 2046.0 369.32\n",
            "<none>                1991.4 370.71\n",
            "- Weight  1     91.56 2083.0 371.61\n",
            "- Abdo    1   2265.38 4256.8 463.10\n",
            "\n",
            "Step:  AIC=369.32\n",
            "Bodyfat ~ Weight + Abdo\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "<none>                2046.0 369.32\n",
            "- Weight  1    228.96 2274.9 378.05\n",
            "- Abdo    1   2256.93 4302.9 459.63\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Bodyfat ~ Weight + Abdo, data = bfData)\n",
              "\n",
              "Residuals:\n",
              "    Min      1Q  Median      3Q     Max \n",
              "-9.1441 -2.5621 -0.0781  2.9580  9.0413 \n",
              "\n",
              "Coefficients:\n",
              "             Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept) -47.99121    3.69071  -13.00  < 2e-16 ***\n",
              "Weight       -0.24257    0.06486   -3.74 0.000279 ***\n",
              "Abdo          0.93880    0.07995   11.74  < 2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 4.046 on 125 degrees of freedom\n",
              "Multiple R-squared:  0.7326,\tAdjusted R-squared:  0.7283 \n",
              "F-statistic: 171.2 on 2 and 125 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 3 × 4 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>(Intercept)</th><td>-47.991</td><td>3.691</td><td>-13.003</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>Weight</th><td> -0.243</td><td>0.065</td><td> -3.740</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>Abdo</th><td>  0.939</td><td>0.080</td><td> 11.743</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 3 × 4 of type dbl\n\n| <!--/--> | Estimate | Std. Error | t value | Pr(&gt;|t|) |\n|---|---|---|---|---|\n| (Intercept) | -47.991 | 3.691 | -13.003 | 0 |\n| Weight |  -0.243 | 0.065 |  -3.740 | 0 |\n| Abdo |   0.939 | 0.080 |  11.743 | 0 |\n\n",
            "text/latex": "A matrix: 3 × 4 of type dbl\n\\begin{tabular}{r|llll}\n  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n\\hline\n\t(Intercept) & -47.991 & 3.691 & -13.003 & 0\\\\\n\tWeight &  -0.243 & 0.065 &  -3.740 & 0\\\\\n\tAbdo &   0.939 & 0.080 &  11.743 & 0\\\\\n\\end{tabular}\n",
            "text/plain": [
              "            Estimate Std. Error t value Pr(>|t|)\n",
              "(Intercept) -47.991  3.691      -13.003 0       \n",
              "Weight       -0.243  0.065       -3.740 0       \n",
              "Abdo          0.939  0.080       11.743 0       "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get the same as the Forward stepwise selection."
      ],
      "metadata": {
        "id": "nbcyF6qIqjVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward stepwise selection using AIC\n",
        "# Intercept-only model\n",
        "model.lower = lm(data = bfData, Bodyfat ~ 1)\n",
        "# Full model\n",
        "model.upper = lm(data = bfData, Bodyfat ~ .)\n",
        "model.step = step(model.upper, scope = list(lower = model.lower, upper = model.upper), direction = 'backward', k = 2)\n",
        "summary(model.step)\n",
        "round(summary(model.step)$coef, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CKTXz1pgqor_",
        "outputId": "1eee76b4-a11e-4d95-b269-7ea492511e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start:  AIC=373.2\n",
            "Bodyfat ~ Age + Weight + Height + Neck + Chest + Abdo + Hip + \n",
            "    Thigh + Knee + Ankle + Bic + Fore + Wrist\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Ankle   1      0.15 1898.7 371.21\n",
            "- Age     1      0.76 1899.3 371.25\n",
            "- Knee    1      1.47 1900.1 371.29\n",
            "- Bic     1      1.59 1900.2 371.30\n",
            "- Wrist   1      2.08 1900.7 371.34\n",
            "- Thigh   1      4.24 1902.8 371.48\n",
            "- Chest   1      5.07 1903.7 371.54\n",
            "- Hip     1      8.03 1906.6 371.74\n",
            "- Height  1     10.80 1909.4 371.92\n",
            "- Weight  1     20.62 1919.2 372.58\n",
            "<none>                1898.6 373.20\n",
            "- Fore    1     38.19 1936.8 373.74\n",
            "- Neck    1     56.38 1955.0 374.94\n",
            "- Abdo    1   1088.97 2987.6 429.22\n",
            "\n",
            "Step:  AIC=371.21\n",
            "Bodyfat ~ Age + Weight + Height + Neck + Chest + Abdo + Hip + \n",
            "    Thigh + Knee + Bic + Fore + Wrist\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Age     1      0.84 1899.6 369.26\n",
            "- Bic     1      1.90 1900.6 369.33\n",
            "- Knee    1      1.92 1900.7 369.33\n",
            "- Wrist   1      2.64 1901.4 369.38\n",
            "- Thigh   1      4.15 1902.9 369.48\n",
            "- Chest   1      5.55 1904.3 369.58\n",
            "- Hip     1      7.93 1906.7 369.74\n",
            "- Height  1     11.90 1910.6 370.01\n",
            "- Weight  1     23.59 1922.3 370.79\n",
            "<none>                1898.7 371.21\n",
            "- Fore    1     38.15 1936.9 371.75\n",
            "- Neck    1     57.25 1956.0 373.01\n",
            "- Abdo    1   1125.31 3024.1 428.78\n",
            "\n",
            "Step:  AIC=369.26\n",
            "Bodyfat ~ Weight + Height + Neck + Chest + Abdo + Hip + Thigh + \n",
            "    Knee + Bic + Fore + Wrist\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Knee    1      1.33 1900.9 367.35\n",
            "- Bic     1      1.92 1901.5 367.39\n",
            "- Wrist   1      1.93 1901.5 367.39\n",
            "- Thigh   1      3.37 1903.0 367.49\n",
            "- Chest   1      6.39 1906.0 367.69\n",
            "- Hip     1      8.14 1907.7 367.81\n",
            "- Height  1     12.16 1911.7 368.08\n",
            "- Weight  1     27.13 1926.7 369.08\n",
            "<none>                1899.6 369.26\n",
            "- Fore    1     37.85 1937.4 369.79\n",
            "- Neck    1     56.57 1956.1 371.02\n",
            "- Abdo    1   1346.09 3245.7 435.83\n",
            "\n",
            "Step:  AIC=367.35\n",
            "Bodyfat ~ Weight + Height + Neck + Chest + Abdo + Hip + Thigh + \n",
            "    Bic + Fore + Wrist\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Bic     1      2.03 1902.9 365.49\n",
            "- Thigh   1      2.63 1903.5 365.53\n",
            "- Wrist   1      2.73 1903.6 365.53\n",
            "- Chest   1      7.05 1908.0 365.82\n",
            "- Hip     1      7.62 1908.5 365.86\n",
            "- Height  1     11.23 1912.1 366.11\n",
            "<none>                1900.9 367.35\n",
            "- Weight  1     30.51 1931.4 367.39\n",
            "- Fore    1     39.05 1940.0 367.95\n",
            "- Neck    1     55.47 1956.4 369.03\n",
            "- Abdo    1   1345.48 3246.4 433.86\n",
            "\n",
            "Step:  AIC=365.49\n",
            "Bodyfat ~ Weight + Height + Neck + Chest + Abdo + Hip + Thigh + \n",
            "    Fore + Wrist\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Wrist   1      2.79 1905.7 363.68\n",
            "- Thigh   1      4.63 1907.6 363.80\n",
            "- Hip     1      7.50 1910.4 363.99\n",
            "- Chest   1      7.55 1910.5 363.99\n",
            "- Height  1     10.21 1913.1 364.17\n",
            "- Weight  1     29.27 1932.2 365.44\n",
            "<none>                1902.9 365.49\n",
            "- Fore    1     50.40 1953.3 366.83\n",
            "- Neck    1     54.04 1957.0 367.07\n",
            "- Abdo    1   1353.15 3256.1 432.24\n",
            "\n",
            "Step:  AIC=363.68\n",
            "Bodyfat ~ Weight + Height + Neck + Chest + Abdo + Hip + Thigh + \n",
            "    Fore\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Thigh   1      7.00 1912.7 362.14\n",
            "- Hip     1      8.01 1913.7 362.21\n",
            "- Chest   1      9.29 1915.0 362.30\n",
            "- Height  1     13.86 1919.6 362.60\n",
            "<none>                1905.7 363.68\n",
            "- Weight  1     36.34 1942.1 364.09\n",
            "- Fore    1     50.12 1955.8 365.00\n",
            "- Neck    1     79.05 1984.8 366.88\n",
            "- Abdo    1   1372.77 3278.5 431.12\n",
            "\n",
            "Step:  AIC=362.14\n",
            "Bodyfat ~ Weight + Height + Neck + Chest + Abdo + Hip + Fore\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Hip     1      4.42 1917.1 360.44\n",
            "- Chest   1      5.38 1918.1 360.50\n",
            "- Height  1      8.62 1921.3 360.72\n",
            "- Weight  1     29.49 1942.2 362.10\n",
            "<none>                1912.7 362.14\n",
            "- Fore    1     51.53 1964.3 363.55\n",
            "- Neck    1     80.80 1993.5 365.44\n",
            "- Abdo    1   1372.41 3285.1 429.38\n",
            "\n",
            "Step:  AIC=360.44\n",
            "Bodyfat ~ Weight + Height + Neck + Chest + Abdo + Fore\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Chest   1     12.90 1930.0 359.30\n",
            "- Height  1     17.44 1934.6 359.60\n",
            "<none>                1917.1 360.44\n",
            "- Fore    1     59.51 1976.6 362.35\n",
            "- Neck    1     76.42 1993.6 363.44\n",
            "- Weight  1    117.40 2034.5 366.05\n",
            "- Abdo    1   1370.48 3287.6 427.47\n",
            "\n",
            "Step:  AIC=359.3\n",
            "Bodyfat ~ Weight + Height + Neck + Abdo + Fore\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "- Height  1      9.06 1939.1 357.90\n",
            "<none>                1930.0 359.30\n",
            "- Fore    1     59.13 1989.2 361.16\n",
            "- Neck    1     74.35 2004.4 362.14\n",
            "- Weight  1    107.93 2038.0 364.26\n",
            "- Abdo    1   1679.52 3609.6 437.43\n",
            "\n",
            "Step:  AIC=357.9\n",
            "Bodyfat ~ Weight + Neck + Abdo + Fore\n",
            "\n",
            "         Df Sum of Sq    RSS    AIC\n",
            "<none>                1939.1 357.90\n",
            "- Fore    1     52.30 1991.4 359.30\n",
            "- Neck    1     85.21 2024.3 361.40\n",
            "- Weight  1    133.93 2073.0 364.45\n",
            "- Abdo    1   2283.87 4223.0 455.52\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Bodyfat ~ Weight + Neck + Abdo + Fore, data = bfData)\n",
              "\n",
              "Residuals:\n",
              "    Min      1Q  Median      3Q     Max \n",
              "-9.1637 -2.8476  0.0877  2.7522  8.3342 \n",
              "\n",
              "Coefficients:\n",
              "             Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept) -41.88325    8.30967  -5.040 1.62e-06 ***\n",
              "Weight       -0.22932    0.07868  -2.915  0.00423 ** \n",
              "Neck         -0.61856    0.26606  -2.325  0.02172 *  \n",
              "Abdo          0.98046    0.08146  12.036  < 2e-16 ***\n",
              "Fore          0.43409    0.23834   1.821  0.07099 .  \n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 3.971 on 123 degrees of freedom\n",
              "Multiple R-squared:  0.7466,\tAdjusted R-squared:  0.7383 \n",
              "F-statistic: 90.58 on 4 and 123 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 5 × 4 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>(Intercept)</th><td>-41.883</td><td>8.310</td><td>-5.040</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>Weight</th><td> -0.229</td><td>0.079</td><td>-2.915</td><td>0.004</td></tr>\n",
              "\t<tr><th scope=row>Neck</th><td> -0.619</td><td>0.266</td><td>-2.325</td><td>0.022</td></tr>\n",
              "\t<tr><th scope=row>Abdo</th><td>  0.980</td><td>0.081</td><td>12.036</td><td>0.000</td></tr>\n",
              "\t<tr><th scope=row>Fore</th><td>  0.434</td><td>0.238</td><td> 1.821</td><td>0.071</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 5 × 4 of type dbl\n\n| <!--/--> | Estimate | Std. Error | t value | Pr(&gt;|t|) |\n|---|---|---|---|---|\n| (Intercept) | -41.883 | 8.310 | -5.040 | 0.000 |\n| Weight |  -0.229 | 0.079 | -2.915 | 0.004 |\n| Neck |  -0.619 | 0.266 | -2.325 | 0.022 |\n| Abdo |   0.980 | 0.081 | 12.036 | 0.000 |\n| Fore |   0.434 | 0.238 |  1.821 | 0.071 |\n\n",
            "text/latex": "A matrix: 5 × 4 of type dbl\n\\begin{tabular}{r|llll}\n  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n\\hline\n\t(Intercept) & -41.883 & 8.310 & -5.040 & 0.000\\\\\n\tWeight &  -0.229 & 0.079 & -2.915 & 0.004\\\\\n\tNeck &  -0.619 & 0.266 & -2.325 & 0.022\\\\\n\tAbdo &   0.980 & 0.081 & 12.036 & 0.000\\\\\n\tFore &   0.434 & 0.238 &  1.821 & 0.071\\\\\n\\end{tabular}\n",
            "text/plain": [
              "            Estimate Std. Error t value Pr(>|t|)\n",
              "(Intercept) -41.883  8.310      -5.040  0.000   \n",
              "Weight       -0.229  0.079      -2.915  0.004   \n",
              "Neck         -0.619  0.266      -2.325  0.022   \n",
              "Abdo          0.980  0.081      12.036  0.000   \n",
              "Fore          0.434  0.238       1.821  0.071   "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We again get the same model."
      ],
      "metadata": {
        "id": "-hJf66cqquzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are some **issues **with stepwise selection approaches. They are:\n",
        "1. The same data is used throughout in both forward and backward stepwise selection approaches.\n",
        "(Typically, this will result in an underestimate of the true prediction error of the model on unseen data.)\n",
        "- **One way to avoid this issue:** The train-test-validation split of the dataset or cross-validation cna be used to address this."
      ],
      "metadata": {
        "id": "r1tH6z0yq2Vb"
      }
    }
  ]
}